<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on dimitraz.github.io</title>
    <link>https://dimitraz.github.io/blog/post/</link>
    <description>Recent content in Posts on dimitraz.github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Aug 2017 14:16:04 +0100</lastBuildDate>
    
	<atom:link href="https://dimitraz.github.io/blog/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>GSoC 2017 with RedHat</title>
      <link>https://dimitraz.github.io/blog/post/gsoc-final-phase/</link>
      <pubDate>Sun, 27 Aug 2017 14:16:04 +0100</pubDate>
      
      <guid>https://dimitraz.github.io/blog/post/gsoc-final-phase/</guid>
      <description>For the last three months I&amp;rsquo;ve worked on the UnifiedPush Server alongside fellow gsocer Polina to come up with a proof of concept for using Apache Kafka as the UPS&amp;rsquo; internal messaging system. Here is a quick a summary of what we did, what can still be improved on and what still has to be done.
Useful links  GSoc 2017 Branch and commits All UPS PRs and Kafka CDI PRs by me GSoC 2017 Jira board  Overall Stats  88 total Jira Tasks created 38 pull requests to the UPS 7 pull requests to Kafka CDI The GSoC branch is 60 commits ahead of the master  What was done With the help of our mentors, we managed to replace the Java Messaging System with a completely Kafka based workflow for push message routing:</description>
    </item>
    
    <item>
      <title>The final phase</title>
      <link>https://dimitraz.github.io/blog/post/week-xiii/</link>
      <pubDate>Wed, 23 Aug 2017 13:16:04 +0100</pubDate>
      
      <guid>https://dimitraz.github.io/blog/post/week-xiii/</guid>
      <description>Since the last Google Summer of Code post a few weeks ago in which I promised to post weekly, I&amp;rsquo;ve mainly worked on the kafka-cdi library, adding custom serializers/deserializers to automatically handle objects of any type T.
Generic serializers and deserializers for Kafka I ran into every problem imaginable - null serializers, problems with the library and problems with abstract class serialization. Here is the list of what was done:</description>
    </item>
    
    <item>
      <title>Evaluation phase II</title>
      <link>https://dimitraz.github.io/blog/post/phase-ii/</link>
      <pubDate>Fri, 28 Jul 2017 14:16:04 +0100</pubDate>
      
      <guid>https://dimitraz.github.io/blog/post/phase-ii/</guid>
      <description>It&amp;rsquo;s week 9 of Google Summer of Code and we&amp;rsquo;ve officially reached the second evaluation phase, which means we only have about four weeks left until our project comes to an end.
This last month has been heavily focused on research (a lot more so than I initally anticipated) and attempting to get more involved in the community, mostly since one of our mentors was away. We faced a few blockers and experienced our fair share of ups and downs but we&amp;rsquo;ve managed to make a fair bit of progress, with support from the community:</description>
    </item>
    
    <item>
      <title>Analysing the UnifiedPush Server</title>
      <link>https://dimitraz.github.io/blog/post/ups-metrics/</link>
      <pubDate>Tue, 25 Jul 2017 13:16:04 +0100</pubDate>
      
      <guid>https://dimitraz.github.io/blog/post/ups-metrics/</guid>
      <description>Attempting to get familiarized with the UPS codebase and its under-the-hood intricacies is a pretty daunting task. A good step in the right direction, for me at least, was attempting to analyse the metrics and the overall quality of the codebase. Having a higher level overview of what is currently there and a vague idea of what can be improved upon is generally a good place to start.
So with that objective in mind we were recommended two tools in particular to play around with, Structure101 and SonarQube.</description>
    </item>
    
    <item>
      <title>Docker for Mac networking</title>
      <link>https://dimitraz.github.io/blog/post/docker-networking/</link>
      <pubDate>Wed, 19 Jul 2017 13:16:04 +0100</pubDate>
      
      <guid>https://dimitraz.github.io/blog/post/docker-networking/</guid>
      <description>When Google Summer of Code first began, one of our first tasks was describing the steps for the required Kafka-Zookeeper setup. The most straightforward and uncomplicated solution was running the UPS locally, while Zookeeper and the Kafka broker would run in two separate Docker containers.
From the very beginning I ran into loads of issues. Producers and consumers could be started easily from within the containers and communicate between themselves at that level.</description>
    </item>
    
    <item>
      <title>The evaluation phase</title>
      <link>https://dimitraz.github.io/blog/post/welcome/</link>
      <pubDate>Sat, 10 Jun 2017 14:16:04 +0100</pubDate>
      
      <guid>https://dimitraz.github.io/blog/post/welcome/</guid>
      <description>It&amp;rsquo;s been four weeks since Google Summer of Code officially started, four weeks in which I&amp;rsquo;ve worked alongside fellow gsocer Polina to integrate the first Kafka producers and consumers in the UnifiedPush Server code base. It has been a pretty good feeling and something I never really imagined I&amp;rsquo;d have the opportunity to work on, but I really couldn&amp;rsquo;t have asked for a better project.
So far, we&amp;rsquo;ve
 Set up the main working environment using Docker containers for Zookeeper and the Kafka Broker - not without a few headaches, but more on this soon.</description>
    </item>
    
  </channel>
</rss>